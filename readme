# PyChat: Your All-in-One AI Chat Client ðŸ¤–ðŸ’¬

[![Screenshot](screenshot.png)](screenshot.png)

Tired of juggling multiple AI platforms? PyChat is a versatile desktop application that unifies **OpenAI (GPT-4, GPT-3.5), Anthropic Claude, Ollama, and Google Gemini** in a sleek, user-friendly PyQt5 interface.

---

## Table of Contents
- [Features](#features)
- [Data & Security](#data--security)
- [Dependencies](#dependencies)
- [Installation](#installation)
- [Setup](#setup)
  - [OpenAI](#setting-up-openai)
  - [Anthropic Claude](#setting-up-anthropic-claude)
  - [Ollama](#setting-up-ollama)
  - [Google Gemini](#setting-up-google-gemini)
- [Usage](#usage)
  - [Preprompts](#preprompts)
  - [Sending Messages](#sending-messages)
  - [Conversation Management](#conversation-management)
  - [Saving Conversations](#saving-conversations)
  - [Model Management](#model-management)
- [Troubleshooting](#troubleshooting)
- [Data Cleanup](#data-cleanup)
- [License](#license)

---

## Features

- **Multi-Provider Support**
  - OpenAI (GPT-4, GPT-3.5, etc.)
  - Anthropic Claude (Claude 3 Opus, Sonnet, Haiku, etc.)
  - Ollama (for local open-source models)
  - Google Gemini

- **Rich Text Interface**
  - Syntax highlighting for code blocks
  - Streaming support for real-time responses
  - "Copy Code" button for easy reuse

- **Advanced Features**
  - Preprompt system for reusable context templates
  - "Show thinking" option for DeepSeek
  - Save and load conversations (JSON and text)
  - Customizable API endpoints
  - Thread-based conversation management
  - AI-to-AI conversation feature

- **User-Friendly Design**
  - Simple and intuitive interface
  - Real-time streaming responses
  - Easy configuration for multiple providers

---

## Data & Security

- **Local Storage**
  - Conversations are stored in an SQLite database (`chat_history.db`)
  - API keys are securely stored using Qt's settings mechanism
  - Debug logs (`ai_chat_debug.log`) may include message content for troubleshooting

- **Privacy**
  - Your conversations are only sent to the AI provider APIs you configure

- **Security Considerations**
  - Keep your computer secure, as API keys are stored locally
  - Be aware of usage costs with providers like OpenAI and Anthropic
  - Ollama allows local model usage without external data transfer

---

## Dependencies

- Python 3.6+
- [PyQt5](https://pypi.org/project/PyQt5/)
- [Requests](https://pypi.org/project/requests/)
- [qtconsole](https://pypi.org/project/qtconsole/)
- [fuzzywuzzy](https://pypi.org/project/fuzzywuzzy/)
- [google-genai](https://pypi.org/project/google-genai/)

---

## Installation

1. **Clone the repository:**
    ```bash
    git clone https://github.com/Magnetron85/PyChat.git
    ```
2. **Install dependencies:**
    ```bash
    pip install PyQt5 requests qtconsole fuzzywuzzy google-genai
    ```
3. **Run the application:**
    ```bash
    python pychat.py
    ```

---

## Setup

### Setting up OpenAI

1. Navigate to the **Settings** tab.
2. Select **OpenAI** from the provider dropdown.
3. Enter your OpenAI API key (get it from the [OpenAI Platform](https://platform.openai.com/)).
4. Click **Save Settings**.

### Setting up Anthropic Claude

1. Navigate to the **Settings** tab.
2. Select **Claude (Anthropic)** from the provider dropdown.
3. Enter your Anthropic API key (from the [Anthropic Console](https://console.anthropic.com/)).
4. Click **Save Settings**.

### Setting up Ollama

1. Install [Ollama](https://ollama.ai/) on your system.
2. Ensure Ollama is running (default URL: `http://localhost:11434`).
3. Use the default URL in PyChat or modify it as needed.
4. Click **Refresh Models** to load your installed Ollama models.

### Setting up Google Gemini

1. Navigate to the **Settings** tab.
2. Select **Gemini (Google)** from the provider dropdown.
3. Enter your Google Gemini API key.
4. Click **Save Settings**.

---

## Usage

### Preprompts

- Click **Preprompt** to expand the panel.
- Click **New** to create a preprompt.
- Enter a name and content, then click **Save**.
- Select your preprompt before sending messages.

### Sending Messages

1. Choose your provider and model.
2. Type your message in the input area.
3. Click **Send** or press `Ctrl+Enter`.
4. Watch the AI's response populate the chat area.

### Conversation Management

- **File > New Thread** starts a new conversation.
- The thread list on the left shows all active conversations.
- Right-click on threads to rename, archive, or delete them.

### Saving Conversations

- Click **Save Chat** to export a text file.
- Use **File > Export Thread** to save the conversation as a JSON file.
- Use **File > Import Thread** to load a JSON conversation.

### Model Management

- **Ollama:** Manage and install models via Ollama.
- **Google Gemini, OpenAI, Anthropic:** Models load automatically when valid API keys are provided.

---

## Troubleshooting

- **Models not loading:** Verify your API keys in **Settings**.
- **Ollama connection issues:** Ensure Ollama is running.
- **Error messages:** Check the `ai_chat_debug.log` for details.
- **API key problems:** Confirm that your keys are correct and active.
- **Database issues:** Verify file permissions for `chat_history.db`.

---

## Data Cleanup

- Delete `chat_history.db` to remove all stored conversations.
- Clear API keys via the **Settings** tab.
- Delete `ai_chat_debug.log` to remove old logs.

---

## License

This project is licensed under the [MIT License](LICENSE).
